# ğŸ“„ tasks/user_scrap_pipeline.py
from sqlalchemy.orm import Session
from models.article import Article
from models.scrap import Scrap
from models.user import User
from models.user import KnowledgeMap
from models.scrap import PCluster, PClusterKeyword, PClusterArticle
from clustering.embedder import make_embeddings, preprocess_text
from clustering.cluster import run_kmeans
from clustering.keyword_extractor import extract_keywords_per_cluster

def run_user_scrap_knowledge_map(user: User, db: Session):
    # 1. í•´ë‹¹ ìœ ì €ì˜ ìŠ¤í¬ë© ê¸°ì‚¬ ë¶ˆëŸ¬ì˜¤ê¸°
    articles = (
        db.query(Article)
        .join(Scrap, Scrap.article_id == Article.id)
        .filter(Scrap.user_id == user.id)
        .all()
    )

    if not articles:
        print(f"âŒ ì‚¬ìš©ì {user.id} ìŠ¤í¬ë© ì—†ìŒ. ê±´ë„ˆëœ€.")
        return

    # 2. ì „ì²˜ë¦¬ + ë¹ˆ í…ìŠ¤íŠ¸ í•„í„°ë§
    texts = [f"{a.title} {a.summary or ''}".strip() for a in articles]
    preprocessed = [preprocess_text(t) for t in texts]

    texts_filtered = []
    articles_filtered = []
    for i, p in enumerate(preprocessed):
        if p.strip():
            texts_filtered.append(p)
            articles_filtered.append(articles[i])

    if not texts_filtered:
        print(f"âŒ ì‚¬ìš©ì {user.id} ìŠ¤í¬ë© ê¸°ì‚¬ ì¤‘ ìœ íš¨í•œ í…ìŠ¤íŠ¸ ì—†ìŒ. ê±´ë„ˆëœ€.")
        return

    # 3. ì„ë² ë”© & í´ëŸ¬ìŠ¤í„°ë§
    embeddings = make_embeddings(texts_filtered)

    # í´ëŸ¬ìŠ¤í„° ìˆ˜ëŠ” ë„ˆë¬´ ë§ì§€ ì•Šê²Œ ì¡°ì ˆ (ìµœì†Œ 2, ìµœëŒ€ 5)
    n_clusters = min(max(2, len(embeddings) // 2), 5)
    labels = run_kmeans(embeddings, n_clusters=n_clusters)

    # 4. KnowledgeMap ìƒì„±
    knowledge_map = KnowledgeMap(user_id=user.id)
    db.add(knowledge_map)
    db.commit()
    db.refresh(knowledge_map)

    # 5. ëŒ€í‘œ í‚¤ì›Œë“œ ì¶”ì¶œ
    keyword_map = extract_keywords_per_cluster(texts_filtered, labels, db)

    for cluster_id in set(labels):
        cluster_articles = [articles_filtered[i] for i, l in enumerate(labels) if l == cluster_id]
        cluster_keywords = keyword_map.get(cluster_id, [])

        pcluster = PCluster(label=cluster_id, knowledge_map_id=knowledge_map.id)
        db.add(pcluster)
        db.commit()
        db.refresh(pcluster)

        for article in cluster_articles:
            db.add(PClusterArticle(article_id=article.id, pcluster_id=pcluster.id))

        for kw in cluster_keywords:
            db.add(PClusterKeyword(keyword=kw, pcluster_id=pcluster.id))

    db.commit()
    print(f"âœ… ì‚¬ìš©ì {user.id} ì§€ì‹ë§µ ì €ì¥ ì™„ë£Œ")



# âœ… ì´ í•¨ìˆ˜ë„ ê°™ì€ íŒŒì¼ ì•„ë˜ì— ìœ„ì¹˜
def generate_user_scrap_knowledge_maps(db: Session):
    users = db.query(User).all()
    for user in users:
        run_user_scrap_knowledge_map(user, db)