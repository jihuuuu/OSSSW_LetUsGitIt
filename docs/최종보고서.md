# 1. 서론 및 프로젝트 개요

## 📌 1.1. 프로젝트 소개

**"요즘 가장 화제가 되는 뉴스 주제를 AI로 한눈에"**

> 저희 서비스는 매일 수집되는 뉴스 기사 수천 건을 AI가 자동 분류 및 클러스터링하여, 요즘 가장 화제가 되는 이슈 주제를 시각적으로 보여주는 웹 기반 서비스입니다.
> 

## 💡 1.2. 기획 배경 및 의도

저희 서비스는 넘쳐나는 뉴스 속에서 **어떤 이슈가 중요한지 한눈에 파악하기가 어려운 문제**에서 출발하였습니다.

기존 포털 사이트들은 정치, 경제, 사회처럼 **넓고 고정된 카테고리 중심의 분류만 제공**하기 때문에, 사용자 입장에서 지금 가장 화제가 되는 이슈나 키워드를 직관적으로 확인하기 어려웠습니다.

이에 저희는 **AI 기반 의미적 유사도 기준의 실시간 클러스터링**을 통해 “가장 화제가 되는 이슈”를 한 눈에 확인하고 시각적으로 보여주는 웹 페이지를 제작하고자 하였습니다.

## 🛠️ 1.3. MVP 목표 및 범위

- 📰 **최신 뉴스 수집**
→ RSS 및 크롤링 기법으로 다양한 언론 피드에서 발행된 뉴스 자동 수집
- 🧩 **클러스터링**
→ AI 기반 의미적 유사도 기준으로 1시간 단위 의미적 군집화
- 🏷 **대표 키워드 추출**
→ 각 클러스터의 핵심 키워드 식별
- 🗣️ **오늘의 이슈**
→ 실시간 클러스터 TOP 20 및 키워드 관계 네트워크 시각화
- 🔍 **뉴스 트렌드**
→ 주간 TOP5 키워드 추이를 통한 트렌드 시각화
- 📌 **스크랩 기능**
→ 스크랩 및 스크랩 조회 페이지 제공
- 📝 **노트 기능**
→ 기사 기반 개인 노트 작성 기능 제공

## 🆚 1.4. 서비스 소개 (타 시장 서비스와의 차별화)

### **1. 실시간 클러스터링**

- 전날 데이터가 아닌, **최근 24시간 이내 뉴스**를 1시간 단위로 자동 클러스터링해 **최신성** 확보

### **2. 다양한 트렌드 시각화 제공**

- 주간 이슈 변화 페이지: 주간 TOP5 키워드의 시간에 따른 추이
    - 언급량 변화를 라인 차트로 시각화해 **직관성** 확보
- 키워드 검색 페이지: 선택된 키워드와 연관된 키워드들 간의 관계 네트워크 그래프와 일주간 추이
    - 이슈 **키워드 추천** 기능을 함께 제공
- 오늘의 키워드: 최근 24시간 내 이슈 키워드들 간의 관계 네트워크 그래프
    - **최근 24시간 이내 뉴스** 기반으로 **최신성** 확보
    - 기존 서비스와 달리 이슈 키워드를 네트워크 그래프로 시각화 하여 **키워드 간 관계를 직관적으로 파악** 가능
    - 기존 서비스는 키워드 선택 시 키워드가 포함된 기사를 모두 나열해 어떤 점이 화제인지 파악 불가
        
        →  키워드 간 엣지 클릭 시 해당 이슈 클러스터 페이지로 이동하여, **어떤 내용이 화제가 되었는지 한눈에 파악** 가능
        

### **3. 개인화 기능**

- 사용자가 기사를 선택 후 노트 생성 가능
    - 이후 열람 시 노트와 관련된 기사들을 함께 볼 수 있어 **정보 정리에 효과적**
- 사용자의 스크랩 데이터를 기반으로 **키워드 간 연결 그래프(지식맵)** 자동 생성
    - 자신의 관심사와 정보 흐름을 시각적으로 확인 가능

## 1.5. 팀 구성 및 역할 분담

| 이름 | 담당 분야 |
| --- | --- |
| **강성경** | 프론트엔드, 디자인, API 설계, 배포 |
| **남지후** | 백엔드, DB 설계, AI, 캐싱 |
| **이채연** | 백엔드, DB 설계, 캐싱, 배포 |
| **조윤경** | 프론트엔드, 디자인, API 설계, AI |

# 2. 시스템 아키텍처 및 기술 스택

## 2.1. 전체 아키텍처 다이어그램

### 1) 디렉토리 구조

**1. 루트 *(OSSSW_LetUsGitIt/)***

```
OSSSW_LetUsGitIt/
├─ README.md           # 프로젝트 설명서
├─ LICENSE             # 라이선스
├─ .gitignore          # 깃 무시 설정
├─ frontend
├─ project
└─ CONTRIBUTING.md     # 기여 가이드 (옵션)
```

---

**2. `project/` *(백엔드/AI/DB)***

```
project/
├─ api/                            # FastAPI 앱, 라우터, 스키마
│  ├─ create_app.py                # 애플리케이션 객체 생성 및 설정
│  ├─ config.py                    # 환경 변수 로드 & 설정 관리
│  ├─ routes/                      # REST API 엔드포인트 모음
│  │  ├─ cluster.py                # 클러스터 조회·관리 API
│  │  ├─ knowledge_map.py          # 사용자 지식맵 생성·조회 API
│  │  ├─ news.py                   # 뉴스 기사 CRUD API
│  │  ├─ notes.py                  # 개인 노트 작성·관리 API
│  │  ├─ scrap.py                  # 스크랩(즐겨찾기) API
│  │  ├─ trend.py                  # 트렌드 키워드 조회 API
│  │  └─ user.py                   # 회원가입·로그인·유저 프로필 API
│  ├─ utils/                       # 공통 유틸리티 함수
│  │  ├─ auth.py                   # OAuth2 / JWT 인증·인가 로직
│  │  ├─ cache.py                  # Redis / 메모리 캐싱 헬퍼
│  │  ├─ cluster.py                # 클러스터 도메인 헬퍼 함수
│  │  ├─ logger.py                 # 로거 설정 및 출력 포맷
│  │  └─ token.py                  # JWT 토큰 생성·검증 유틸리티
│  └─ schemas/                     # Pydantic 모델 스키마 정의
├─ collector/                      # RSS 피드 수집기
│  ├─ rss_list.py                  # 구독할 RSS URL 목록 관리
│  └─ rss_collector.py             # RSS 크롤링 및 기사 데이터 파싱
├─ clustering/                     # AI 기반 클러스터링 & 임베딩
│  ├─ cache_redis.py               # Redis 캐시 연동
│  ├─ cluster.py                   # 클러스터 생성·업데이트 로직
│  ├─ embedder.py                  # SBERT 임베딩 생성 모듈
│  ├─ evaluate_by_topic.py         # 클러스터링 품질 평가
│  ├─ evaluate_keyword_quality.py  # 키워드 품질 평가
│  ├─ keyword_extractor.py         # 대표 키워드 추출 로직
│  ├─ pipeline_by_topic.py         # 토픽별 파이프라인 실행
│  └─ running_stage.py             # 클러스터링 파이프라인 단계별 모듈
├─ database/                       # DB 연결 & 의존성
│  ├─ connection.py                # SQLAlchemy 엔진·세션 생성
│  └─ deps.py                      # FastAPI 의존성 주입 모듈
├─ data/                           # 데이터, 임베딩 등
├─ dummy/                          # 테스트용/샘플데이터/로직
├─ models/                         # SQLAlchemy ORM 모델들
├─ tasks/                          # 지식맵 파이프라인, 트렌드 파이프라인
├─ app.py                          # FastAPI 앱 실행 진입점
├─ .env                            # 환경 변수
├─ db_init.py                      # DB 초기화
├─ requirements.txt                # 패키지 명세
├─ docker-compose.yml              # 도커 컴포즈 설정
└─ Dockerfile                      # 컨테이너 빌드

```

---

**3. `frontend/` *(React/Vite/Tailwind)***

```python
frontend/
├── public/                                 // 정적 파일(이미지, favicon 등) 폴더
│   └── ...                                
├── src/                                    // 소스 코드 루트
│   ├── components/                         // 재사용 UI 컴포넌트 폴더
│   │   ├── Header.tsx                      // 상단 헤더 컴포넌트
│   │   ├── NoteAccordionList.tsx           // 노트 목록 아코디언 컴포넌트
│   │   └── ui/                             // UI 라이브러리 컴포넌트
│   │       └── accordion.tsx               // 아코디언 UI 컴포넌트
│   ├── hooks/                              // 커스텀 훅 폴더
│   │   └── useLogoutWatcher.ts             // 로그아웃 감시 훅
│   ├── pages/                              // 라우트별 페이지 컴포넌트 폴더
│   │   ├── ClusterDetailPage.tsx           // 클러스터 상세 페이지
│   │   ├── DashboardPage.tsx               // 대시보드(메인) 페이지
│   │   ├── HomePage.tsx                    // 홈(메인) 페이지
│   │   ├── KeywordDetailPage.tsx           // 키워드 상세 페이지
│   │   ├── Login.tsx                       // 로그인 페이지
│   │   ├── NoteCreatePage.tsx              // 노트 생성 페이지
│   │   ├── NoteEditPage.tsx                // 노트 편집 페이지
│   │   ├── NotePage.tsx                    // 노트 전체 목록 페이지
│   │   ├── ScrapbookPage.tsx               // 스크랩북(기사 모음) 페이지
│   │   ├── SignupCompletePage.tsx          // 회원가입 완료 페이지
│   │   ├── SignupPage.tsx                  // 회원가입 페이지
│   │   └── TodayIssuePage.tsx              // 오늘의 이슈 페이지
│   ├── routes/                             // 라우터 관련 파일 폴더
│   │   ├── AppRouter.tsx                   // 전체 라우팅 설정
│   │   └── TrendRoutes.tsx                 // 트렌드 관련 라우팅
│   ├── services/                           // API 호출 등 서비스 함수 폴더
│   │   └── note.ts                         // 노트 관련 API 함수
│   ├── types/                              // 타입 정의 폴더
│   │   ├── article.ts                      // 기사 타입 정의
│   │   └── note.ts                         // 노트 타입 정의
│   ├── App.tsx                             // 앱 루트 컴포넌트
│   └── main.tsx                            // 앱 진입점(엔트리포인트)
├── package.json                            // 프로젝트 의존성 및 스크립트
└── tsconfig.json                           // 타입스크립트 설정
```

### 2) 서버 구조

**Browser**, **Frontend**, **Backend**, **Redis**, **MySQL** 5개 컴포넌트 간의 주요 통신 흐름을 보여줍니다.

- **Browser ↔ Frontend (5173)**
    - React/Vite 개발 서버가 호스팅하는 UI
    - 사용자의 인터랙션을 받아 백엔드 API 호출
- **Frontend ↔ Backend (8000)**
    - FastAPI(Uvicorn) 기반 REST API
    - 클러스터링, 트렌드, 키워드 검색 등 주요 비즈니스 로직 제공
- **Backend ↔ Redis (6379)**
    - 임베딩 벡터, 지식맵, API 응답 캐싱
    - `redis.asyncio` + `fastapi-cache2` 비동기 캐시 레이어
- **Backend ↔ MySQL (3306)**
    - SQLAlchemy ORM을 통한 데이터 읽기/쓰기
    - 사용자, 기사, 클러스터, 키워드, 트렌드 등 영속화

## 2.2. UML

### 1) Domain Model

![image.png](attachment:7b9ef58a-fa07-42bc-b98d-ec0a03f3a2fa:image.png)

### 2) Class Diagram

![image.png](attachment:e641469e-927e-4bd6-ac1a-586463bdde57:image.png)

## 2.3. 인프라 구성

### 1) 개발 환경

- **Docker Compose**
    - `docker-compose.yml`에 정의된 서비스로 로컬 개발 환경을 구성
        - **backend**: FastAPI(Uvicorn) 앱
        - **mysql**: MySQL 8.0 데이터베이스
        - **redis**: Redis 캐싱 서버
    - 각 서비스는 전용 브리지 네트워크로 연결되며, `.env` 파일에서 환경변수를 로드하도록 설정
- **Dockerfile**
    - `backend` 컨테이너용으로 Python 3.10 이미지를 기반
    - 애플리케이션 코드 복사 → 의존성 설치(`requirements.txt`) → Uvicorn 실행
    - `echo=False`로 SQLAlchemy 로그 최소화, `pool_pre_ping=True`로 DB 연결 안정화

### 2) 스케줄러

- **APScheduler (AsyncIOScheduler)**
    - `create_app.py`에서 `create_scheduler()`를 통해 스케줄러를 초기화
    - **매시 정각**에 `hourly_clustering` 잡 실행
    - **매일 자정(00:00 KST)**에 `generate_daily_trend` 잡 실행
    - `coalesce=True`, `misfire_grace_time=600` 설정으로 실행 누락 시 최대 10분 유예 후 실행

### 3) 캐시

- **Redis**
    - 개발: Docker Compose 내 Redis 컨테이너
- **캐싱 레이어**
    - **임베딩 벡터**: `cache_redis.py`의 `save_embedding_cache`로 토픽별 임베딩을 TTL = `since_hours × 3600s`로 저장
    - **API 응답**: `FastAPI-Cache2` + `redis.asyncio`를 사용해 주요 라우터 응답 캐시 (기본 TTL = 300s)

### 4) 배포 환경 (AWS + Docker)

- **컨테이너 레지스트리**: AWS ECR에 Docker 이미지 저장
- **컨테이너 서비스**: AWS ECS Fargate (또는 EC2 + Docker)
    - **backend** 서비스: FastAPI 앱 (포트 8000)
    - **scheduler**: 동일 컨테이너 내에서 APScheduler 실행
- **데이터베이스**: AWS RDS for MySQL (3306)
- **캐시**: AWS ElastiCache for Redis (6379)
- **정적 자산**: React 빌드 파일을 S3에 업로드 후 CloudFront로 서빙 (HTTPS 443)
- **부하 분산**: ALB(Application Load Balancer)를 통해 `/api/*` 트래픽은 backend, 정적 요청은 S3로 라우팅
- **CI/CD**:
    - GitHub Actions → Docker 빌드 → ECR 푸시 → ECS 서비스 롤링 업데이트
    - 블루/그린 배포 및 자동 롤백 설정

## 2.4. 사용 기술 및 라이브러리

- **언어 / 웹 프레임워크**
    - Python 3.10
    - FastAPI (Pydantic)
    - Uvicorn
    - React.js, Vite
    - D3.js, TailwindCSS
- **데이터베이스**
    - MySQL
    - SQLAlchemy ORM
- **웹 크롤링 / HTTP**
    - feedparser, requests
- **AI / NLP / 알고리즘**
    - sentence-transformers (jhgan/ko-sbert-sts)
    - KoNLPy (Okt)
    - scikit-learn, numpy, scipy
    - hdbscan, umap-learn
- **배치 / 스케줄링**
    - APScheduler
- **캐싱 / 검색**
    - Redis
    - FastAPI-Cache2
- **인증 / 보안 / 설정**
    - python-jose[cryptography] (JWT)
    - passlib[bcrypt] (비밀번호 해싱)
    - python-dotenv, pydantic-settings
- **테스트 / 유틸리티**
    - Faker (더미 데이터 생성)
- **DevOps / CI·CD / 모니터링**
    - Docker, Docker Compose

# 3. 구현 기능 상세 설명

## 🏷️ 3.1. 오늘의 이슈

> 최근 24시간 이내의 뉴스를 클러스터링하여 가장 주목받는 주제를 선별하여 보여줍니다.
> 

![image.png](attachment:edf1bc77-eb86-4d30-904a-abd80dfcb172:image.png)

해당 기능은 홈페이지 접속 시 가장 먼저 보여지는 메인 메뉴입니다.

화제성 높은 뉴스 주제를 순위별로 확인할 수 있으며,

**[더보기]** 버튼을 클릭하면 **오늘의 이슈 Top 20**을 한눈에 볼 수 있는 페이지로 이동합니다.

![KakaoTalk_Photo_2025-06-22-00-13-25.png](attachment:3d745ed1-2ad4-4484-a3e4-d6896e069bde:d09033a1-053c-4134-bb73-4c504667ff33.png)

오늘의 이슈 Top 20을 확인할 수 있는 페이지로, 각 주제별 관련 기사 2건이 함께 제공되어 사용자가 이슈 내용을 빠르게 파악하고 원하는 주제를 선택할 수 있도록 합니다.

**[더보기]** 버튼 클릭시 해당 주제와 관련된 전체 기사 목록 페이지로 이동합니다.

![image.png](attachment:d632b269-3153-4eb2-bb62-7c95d02908e9:image.png)

선택한 주제와 관련된 모든 기사를 확인할 수 있으며 기사 제목을 클릭하면 원문 페이지로 이동합니다.

로그인 상태에서, 별표 아이콘을 클릭하면 해당 기사를 스크랩할 수 있습니다.

## ✏️ 3.2. 노트 기능

> 관심있는 기사를 선택해 노트를 작성하고 정리할 수 있습니다.
> 

![스크린샷 2025-06-22 오전 12.32.46.png](attachment:71aef6e8-56a9-475d-a2a8-f9dfbe0a6374:6db9036b-4828-484c-9548-787120525b93.png)

로그인 상태에서, 기사 목록 페이지의 하단에 있는 연필 아이콘을 클릭하면 노트를 작성할 수 있습니다.

![스크린샷 2025-06-22 오전 12.33.19.png](attachment:d3896432-9a23-4cd8-96ba-fd5faeb5d58a:4319ea19-29c7-4fa1-b431-c4aacaa589aa.png)

노트로 정리하고 싶은 기사를 선택한 후, **[새 노트 생성]** 버튼을 클릭하면 새로운 노트를 작성할 수 있습니다.

**[기존 노트에 추가]** 버튼을 클릭하면 선택한 기사를 기존 노트에 추가할 수 있습니다.

![스크린샷 2025-06-22 오전 12.34.44.png](attachment:0182e9c2-2a2f-4d05-b828-b745d9da8f66:d1404e7e-19e8-42d6-865f-51a77df3d2fb.png)

노트 작성 페이지에서 제목과 내용을 입력하여 노트를 작성할 수 있습니다. 

![스크린샷 2025-06-22 오전 12.34.56.png](attachment:9adce15d-bf39-4ce6-8be8-aed1a1129708:233a594b-48a6-4e13-8cc2-0460a2185c65.png)

작성한 노트는 마이페이지의 노트 메뉴에서 확인할 수 있습니다. 

제목을 기준으로 검색이 가능하며, 노트의 추가·수정·삭제가 가능합니다.

## 📊  3.3. 트렌드 시각화

> **매일의 주요 이슈나 일주일간 화제가 된 뉴스의 변화를 시각화하여 제공합니다.** 이를 통해 전체적인 뉴스 트렌드를 한눈에 파악할 수 있으며, 사용자가 관심사에 따라 키워드를 선택해 해당 이슈의 흐름을 확인할 수도 있습니다.
> 

### 🔡 오늘의 키워드

![image.png](attachment:b6d4092e-2d9a-4c2b-9079-9859014d24ff:image.png)

홈페이지 하단에서 확인할 수 있으며 오늘의 이슈 Top10의 키워드와 관계를 확인할 수 있습니다.

간선을 클릭하면 해당 클러스터와 관련된 전체 기사 목록 페이지로 이동합니다.

### 📈 주간 이슈 변화

![image.png](attachment:51de5ecf-5b62-464b-b5ed-548a408139c7:image.png)

홈페이지나 상단바의 트렌드 메뉴를 선택해서 확인할 수 있는 페이지입니다.

일주일간 가장 언급량이 많았던 Top 5 키워드를 이주의 키워드로 보여주며 라인 차트에서 언급량 추이를 확인할 수 있습니다. 

차트에서 마우스 호버를 통해 해당 일자의 기사수를 확인할 수 있습니다.

### 🔎 키워드 검색

![image.png](attachment:627b31ac-778e-4b73-9c00-8145b58244e3:image.png)

일주일동안 집계된 이슈 키워드를 사전순으로 정렬해 제공합니다. 

![image.png](attachment:1d581f74-1632-465d-80b3-9126bd16c8c2:image.png)

관심 있는 키워드를 클릭하면, 해당 키워드의 최근 7일간 일별 등장 횟수와 연관 클러스터·대표 키워드를 함께 확인할 수 있습니다.

## 🧑‍💻 3.4. 마이페이지

> 회원가입 시 마이페이지가 생성되며, 스크랩한 기사와 작성한 노트를 한곳에서 확인할 수 있습니다. 또한, 스크랩 데이터를 기반으로 생성된 지식맵을 통해 **자신의 관심사를 한눈에 확인할 수 있습니다.**
> 

![image.png](attachment:55138fa3-c82e-4e9d-bfc6-7e6ec6349fb8:image.png)

스크랩한 기사를 기반으로 사용자의 관심사를 시각화한 **지식맵**을 제공합니다.

**지식맵** 화면에서 키워드(노드)와 유사도(엣지)로 구성된 그래프를 확인할 수 있으며, 개별 노드를 클릭하면 해당 키워드와 관련된 기사를 열람할 수 있습니다. 

![image.png](attachment:d6846981-63c1-46a8-a574-f201d93485d7:image.png)

마이페이지의 스크랩 메뉴에서 **[more+]** 버튼 클릭시 스크랩한 기사를 확인할 수 있으며, 제목을 기준으로 검색도 가능합니다.

# 4. 기술적 도전 과제 및 해결 방안

## **🎨 4.1. 프론트엔드**

## 1) 기사 선택 상태 유지 (페이지 전환 시)

### **목표**

사용자가 클러스터 상세 페이지에서 체크박스 선택 후, 다른 페이지를 갔다가 돌아와도 **선택한 기사 상태 유지**

### 기술적 도전 과제

- `useState`만 사용하면 페이지 이동 시 컴포넌트가 언마운트되어 `selectedArticles`가 초기화됨

### 해결 방안

- `localStorage` 기반 상태 저장/복원 추가
- 체크박스 선택 시 `addSelectedArticle(id)` 호출 → localStorage에 저장
- 컴포넌트 마운트 시 localStorage 값 복원 → `setSelectedArticles()` 적용

---

## 2) 로그인 상태 처리

### 목표

- 로그인 상태에 따라 **노트 작성 버튼 유무 제어**
- 로그아웃 시 페이지 내에서도 자동 감지하여 **홈으로 리디렉션**

### 기술적 도전 과제

- 토큰 만료 또는 수동 로그아웃 시 UI가 갱신되지 않음
- 로그인 여부를 상태로 반영하고 각 컴포넌트에서 **일관되게 동작시켜야 함**

### 해결 방안

- `localStorage.getItem("accessToken")` 기반 로그인 상태 판별
- `useEffect`에서 로그인 여부 확인 후 `isLoggedIn` 상태 초기화
- 버튼 렌더링 시 조건부로 `isLoggedIn` 확인
- `useLogoutWatcher` 커스텀 훅 생성
    - `window.addEventListener("storage")`로 로그아웃 감지
    - 감지 시 자동으로 홈으로 `navigate("/")` 처리
- 필요 페이지에서 해당 훅 추가로 로그아웃 감지 가능

---

## 3) 기사 스크랩 여부 동기화

### 목표

기사 리스트 렌더링 시 **스크랩 여부를 UI에 즉시 반영**

### 기술적 도전 과제

- 서버에서 응답을 기다리는 동안 **깜빡임 발생**
- 서버 상태와 UI 상태가 일치하지 않아 **불편한 UX**

### 해결 방안

- `localStorage`에 스크랩된 기사 ID 배열 캐싱
- 렌더링 시 `getScrappedArticles()`를 통해 로컬 상태 우선 활용
- 서버 응답과 병합하여 `Set<number>`로 구성 후 사용

---

## 4) 노트 편집 기능 (기사 병합 처리)

### 목표

- 사용자가 스크랩북/클러스터 페이지에서 선택한 기사를 기존 노트에 **추가**
- 노트 편집 페이지에서도 스크랩 기사 **선택 후 추가** 가능

### 기술적 도전 과제

- **노트 편집 화면**에서 들어왔는지, 단순 추가 모드인지 **구분 필요**
- 페이지 간 이동이 많아, 상태가 유지되어야 함
예: `기사 선택 → 노트 선택 → 편집 화면에서 병합`

### 해결 방안

- 페이지 간 상태 전달에 `location.state` 활용
- `useEffect`에서 `location.state.newArticles` 감지
    - 기존 기사 fetch 이후 병합 (`setArticles()`)
    - `Set`, `Map` 등 자료구조 활용해 **중복 제거**
- 편집 버튼 클릭 시 `mode: edit-note` or `select-note` 값 전달하여 분기 처리

---

## 5) 반응형 레이아웃 구현

### 목표

모바일/태블릿/데스크탑 등 다양한 해상도에서 UI가 일관되게 보이도록 구현

### 기술적 도전 과제

- 각 페이지에서 **요소 간 배치/여백**이 브레이크포인트별로 깨짐
- 버튼 그룹, 카드 레이아웃 등이 좁은 화면에서 밀리거나 줄바꿈 발생

### 해결 방안

TailwindCSS의 반응형 유틸리티 클래스 적극 활용

| 문제 | 해결 방법 |
| --- | --- |
| 요소 겹침 | `flex-wrap`, `w-full`, `min-w-0` |
| 가운데 정렬 안 됨 | `mx-auto`, `text-center`, `items-center` |
| 반응형 너비 제한 | `max-w-7xl`, `w-full`, `md:w-1/2` 등 |
| 버튼 세로 정렬 깨짐 | `flex`, `flex-wrap`, `gap-2`, `md:flex-row`, `basis-1/2` |

---

## 6) 뉴스 트렌드 페이지 공통 레이아웃

### 목표

뉴스 트렌드 기능(주간 이슈 변화, 키워드 검색)을 하나의 UI에서 탭으로 전환

- 전체 페이지 리렌더링 없이 콘텐츠만 전환되도록 구성

### 기술적 도전 과제

- URL에 따라 콘텐츠 변경
- 레이아웃은 유지, 콘텐츠만 리렌더링 되어야 함

### 해결 방안

- `react-router-dom`의 **중첩 라우팅** 사용
    - 공통 레이아웃: `TrendLayout`
    - 하위 라우트: `WeeklyIssuePage`, `KeywordIssuePage`
- 탭 클릭 시 `/trend/weekly`, `/trend/search`로 이동 (`Navigate`)
- `<Outlet />`을 통해 TrendLayout 아래에서 자식 라우트만 갱신

---

## 7) D3 지식맵 그래프 개선 (간선 스타일)

### 목표

간선의 weight에 따라 색상 차등 적용

텍스트 노드에 직접 간선이 닿도록 조정

### 기술적 도전 과제

- 노드가 circle이 아니라 text 형태이므로 위치 보정 필요
- weight값을 기준으로 간선 색을 다르게 설정 필요

### 해결 방안

- `d3.link()` 위치 계산 로직 수정하여 간선이 텍스트 위치에 맞게 조정
- weight 구간별로 색상 지정 (`>=0.8` 진한 회색 등)

---

## **🛠️ 4.2. 백엔드**

---

## 1) 사용자 지식맵 API 500 오류 (ResponseValidationError)

### 목표

유저가 스크랩한 기사 중 특정 키워드와 연결된 기사만 조회하는 API를 구현

### 기술적 도전 과제

- `ArticleOut` 스키마에는 `article_id`가 필수인데, 실제 응답 객체에는 `id` 필드만 존재
- FastAPI의 응답 모델 검증 실패로 500 오류 발생

### 해결 방안

- `article_id` → `id`로 이름 통일 필요
- 선택 ①: 스키마 필드를 `id`로 변경하고 전 API에서 동일하게 수정
- 선택 ②: 기존 `article_id` 유지하고, 응답 구성 시 명시적으로 `article_id=article.id`로 설정 → ✅ 현재 선택된 방식

---

## 2) Redis 기반 지식맵·임베딩 캐싱

### 목표

- **지식맵 계산 결과**와 **토픽별 문서 임베딩**을 Redis에 저장하여 AI 파이프라인의 반복 연산을 최소화하고 처리 속도를 개선

### 기술적 도전 과제

- **지식맵**
    - 스크랩 데이터가 변경될 때마다 노드·엣지 재생성 비용이 큼
    - 동시 다중 사용자 요청 시 연산 중복 발생
- **임베딩**
    - SBERT 모델 호출 비용이 높아 대량 텍스트 처리 시 큰 지연
    - 임베딩 결과(벡터)의 효율적 저장·조회 방식 필요
- **캐시 무효화**
    - 데이터 변경 시점에 맞춘 TTL 관리 또는 강제 무효화 로직 부재

### 해결 방안

- **임베딩 캐시** (`clustering/cache_redis.py`)
    - 키 패턴: `emb:{topic}`
    - `save_embedding_cache(ids, embs, topic, ttl)`로 Hash 구조에 pickle 직렬화된 벡터 저장, 기본 TTL=24시간
    - `running_stage.py`에서 `since_hours * 3600`초로 TTL 동적 설정
    - 재사용 시 `load_embedding_cache(topic)`으로 일괄 로드
- **지식맵 캐시** (`user_scrap_pipeline.py` + `api/utils/cache.py`)
    - 키 패턴: `user:{user_id}:knowledge_map`
    - 노드·엣지 리스트를 JSON 직렬화해 `set_cache(key, value)`로 Redis 저장 (기본 TTL=3600초)
    - 스크랩 추가/삭제 API 호출 시 `cache.delete(key)` 혹은 TTL 만료 유도
- **캐시 헬퍼 모듈**
    - `api/utils/cache.py`의 `get_cache`/`set_cache` 함수로 Redis 연결(`settings.REDIS_*`) 및 문자열(JSON) 캐싱 일원화

---

## 3) API 응답 향상을 위한 Redis 캐싱 레이어 도입

### 목표

- **/today**, **/today/{cluster_id}/articles** 등 빈번 호출되는 REST API의 응답 속도 개선
- 데이터베이스 및 네트워크 왕복 부하 경감

### 기술적 도전 과제

- 동일 파라미터 요청마다 매번 DB 조회로 인한 지연
- 캐시 적용 후 TTL 설정이 부적절할 경우 **최신성** 저하 혹은 **불필요한 캐시 낭비**

### 해결 방안

- **FastAPI-Cache2 + redis.asyncio** 설정 (`create_app.py`)
    - `FastAPICache.init(RedisBackend(Redis(...)), prefix="fastapi-cache")`로 Redis 캐시 레이어 초기화
- **엔드포인트별 캐시 데코레이터**
    - `@cache(expire=3500)` 적용: `/today`, `/today/{cluster_id}/articles`에 1시간(≈3600s) 캐싱
    - 필요 시 `expire` 값을 `/clusters`(5분), `/trends`(1시간) 등으로 조정
- **키 생성 전략**
    - 요청 경로 + 쿼리스트링 해시를 캐시 키로 사용하여 파라미터별 분리 캐싱
- **Cache-Control 헤더 설정**
    - 클라이언트 측 브라우저 캐싱 유도 (`Cache-Control: public, max-age=xx`)
- **Cache Warm-up**
    - 스케줄러 실행 직후 주요 API를 내부 호출하여 캐시 선예열

---

## 4) DB 성능 최적화 (인덱스 & 쿼리 튜닝)

### **목표**

복잡한 조인·집계 쿼리도 수 밀리초 내에 처리 가능하도록 데이터베이스 성능을 개선

### **기술적 도전 과제**

- **검색·필터링 컬럼 index**
    - `article.published`와 `article.fetched_at`에 인덱스가 없어 날짜 기반 조회 시 풀 테이블 스캔이 발생
- **관계형 매핑 테이블 인덱스 부족**
    - `scrap`, `cluster_article`, `pkeyword_article` 등 다대다 매핑 테이블의 FK 컬럼에 인덱스가 없어 연결 조회 시 성능 저하
- **과도한 Eager Loading**
    - `fetch_top_clusters` 내부에서 `joinedload`를 중첩 사용해 메모리·CPU 오버헤드 발생

### **해결 방안**

1. **필터링 컬럼 인덱스 추가**
    - 날짜 조회 빈도가 높은 `published`, `fetched_at` 필드에 인덱스 설정
2. **매핑 테이블 복합 인덱스 도입**
    - `scrap(user_id, article_id)`, `cluster_article(cluster_id, article_id)`, `pkeyword_article(pkeyword_id, article_id)` 등에 복합 인덱스 추가
3. **ORM 쿼리 최적화**
    - 필요하지 않은 `joinedload` 제거하고, `selectinload` 등으로 관계 로딩 최소화
    - `load_only`를 사용해 필요한 컬럼만 선별 로드
4. **페이징·커서 기반 페이지네이션**
    - 대량 데이터 스크롤 시 커서 기반 방식으로 응답 구획화
5. **DB 커넥션 풀 튜닝**
    - SQLAlchemy `pool_pre_ping=True`, 적절한 `pool_size` 설정으로 연결 안정성 및 재사용성 강화

---

## 5) 스케줄러 안정성 및 배치 견고성

### **목표**

`hourly_clustering`과 `generate_daily_trend` 같은 배치 잡이 **누락 없이**, **단일 인스턴스**에서만 안정적으로 실행

### **기술적 도전 과제**

- **미스파이어(misfire)** 발생 시 작업이 건너뛰어 버릴 수 있음
- **다중 인스턴스 동시 실행**으로 인한 중복 연산
- **동시성 초과** 시 `max_instances` 기본값으로 잡 타임아웃

### **해결 방안**

1. **스케줄러 옵션 강화**
    - `coalesce=True`로 여러 누락된 실행을 하나로 합치고, `misfire_grace_time`으로 누락 보완
    - `max_instances=1`로 동일 잡의 중복 실행 방지
2. **분산 락(Redlock) 적용**
    - Redis 기반 락을 통해 멀티 노드 환경에서도 단일 노드에서만 잡 실행 보장
3. **잡 상태 영속화**
    - RedisJobStore 혹은 DB-backed job store로 스케줄러 상태와 예약 목록을 영속화
4. **모니터링 & 헬스체크**
    - APScheduler 메트릭을 Prometheus에 노출하고 Grafana 대시보드로 수행률·실패율 시각화

---

## 🧠 4.3. AI 및 데이터 처리

---

## 1) 텍스트 전처리 정확도 확보

### **목표**

한국어 뉴스 기사의 노이즈(HTML 태그, URL, 특수문자 등)를 제거하고, 의미 있는 형태소만 남겨 downstream 임베딩·클러스터링 품질을 향상

### **기술적 도전 과제**

- 불완전한 정규표현식으로 HTML·URL 제거 시 잔여 특수문자가 남음
- 형태소 분석 결과에 보조 동사·조사 등 의미 없는 토큰이 포함
- 전처리 후 재결합된 문자열이 실제 의미 단위와 어긋날 수 있음

### **해결 방안**

- `preprocess_text`에서 정규표현식으로 HTML, URL, 특수문자 제거 후 공백 정리
- KoNLPy Okt로 형태소 분석 → 명사·동사·형용사만 선별, 불용어 집합(`STOPWORDS_KO`) 적용
- 형태소 토큰을 공백으로 결합해 한국어 문맥 단절 최소화

---

## 2) 임베딩 생성 및 캐싱 병목 해결

### **목표**

SBERT 모델 호출 비용을 줄이고, 토픽별 임베딩 결과를 재사용하여 전체 파이프라인 처리 속도를 개선

### **기술적 도전 과제**

- `SentenceTransformer.encode` 호출 지연이 AI 파이프라인 전체 성능을 저해
- 동일 토픽에 대해 매시마다 임베딩을 재생성하면 불필요한 연산 및 I/O 발생

### **해결 방안**

- `make_embeddings` 배치 처리 및 L2 정규화 적용
- `save_embedding_cache`/`load_embedding_cache` 로 Redis Hash에 토픽별 벡터 캐싱 (TTL = since_hours×3600초)

---

## 3) 차원 축소 및 클러스터링 품질 최적화

### **목표**

고차원(SBERT 768차원) 임베딩을 저차원으로 축소한 뒤 HDBSCAN/KMeans/DBSCAN을 적용해 의미 있는 군집을 생성

### **기술적 도전 과제**

- 고차원 임베딩에서 클러스터 경계가 모호해 품질 저하
- 토픽별 최적 파라미터(k, min_cluster_size 등) 설정의 어려움
- 대량 데이터 처리 시 UMAP·HDBSCAN 연산 비용 과다

### **해결 방안**

- UMAP(n_neighbors, min_dist)으로 768→10차원 축소 후 클러스터링 수행
- `pipeline_by_topic.py` 내 토픽별 파라미터 오버라이드 매핑으로 동적 튜닝
- `evaluate_by_topic.py` 스크립트로 Silhouette 점수 자동 계산 및 로그 출력

---

## 4) 대표 키워드 추출 정확도 향상

### **목표**

각 클러스터의 핵심 이슈를 잘 드러내는 키워드를 선별해 사용자에게 직관적인 요약 제공

### **기술적 도전 과제**

- 짧은 뉴스 제목·요약에서 TF-IDF만으로는 의미 있는 키워드가 부족
- 클러스터별 문서 수가 적으면 통계적 신뢰도 저하
- 글로벌 IDF와 로컬 TF 결합 시 정규화 필요

### **해결 방안**

- `extract_top_keywords`에서 글로벌 TF-IDF 모델 학습 후 클러스터별 로컬 TF×글로벌 IDF 적용
- N-gram(1~2그램) 후보 생성 및 `min_df` 기준으로 필터링
- 문서 수가 기준 이하인 클러스터는 예외 처리(“no_keyword”) 방어 코드 도입

---

## 5) 클러스터 품질 평가 및 하이퍼파라미터 튜닝 자동화

### **목표**

각 토픽별 클러스터링 결과를 주기적으로 평가하여 최적 파라미터를 자동으로 추천·반영

### **기술적 도전 과제**

- 토픽마다 적절한 클러스터 개수(k)나 `min_cluster_size` 값이 달라 수작업 튜닝 비용이 큼
- 여러 품질 지표(Silhouette, HHI, Entropy, Gini, Top-k Ratio)를 통합 해석해야 함
- 평가 스크립트를 개별 실행해야 해 자동화 파이프라인 구축이 미비

### **해결 방안**

- `evaluate_by_topic.py`로 매시·매일 Silhouette 점수 계산 및 로그화
- `evaluate_keyword_quality.py`로 HHI, Entropy, Gini, Top-k Ratio 지표 산출 후 JSON 리포트 생성
- 주기 배치(`pipeline_by_topic.py`) 시 자동 호출해 토픽별 최적 `n_clusters`, `eps`, `min_samples` 파라미터 매핑 갱신

# 5. 향후 계획 및 개선 방안

## 5.1. 프론트엔드

- **코드 스플리팅 및 레이지 로딩 도입**
    
    대시보드·클러스터 뷰 컴포넌트를 동적으로 로드해 초기 번들 크기를 줄이고, 사용자가 필요할 때만 로드되도록 개선합니다.
    
- **PWA 지원 및 오프라인 캐싱**
    
    Service Worker를 활용해 주요 페이지를 오프라인에서도 조회 가능하게 하고, 속도 저하 없는 빠른 재방문 경험을 제공합니다.
    

## 5.2. 백엔드

- **DB 성능 지속 개선**
    
    뉴스 수집 및 사용자 활동 증가에 따라 DB 트래픽이 지속적으로 늘고 있어, 일부 페이지의 응답 속도가 지연되는 문제가 발생하고 있습니다. 이에 대응하기 위해 주요 쿼리에 대한 인덱싱, 쿼리 구조 개선 등 다양한 방법으로 DB 부하를 분산하고 시스템 응답 속도를 개선할 예정입니다. 주요 쿼리·조인 패턴을 주기적으로 점검하고, 인덱스·파티셔닝·커서 기반 페이지네이션을 강화해 대용량 트래픽에도 수 ms 응답을 유지합니다.
    
- **자동화된 백업 및 복구 체계 구축**
    
    현재는 수동 백업 방식 위주로 데이터 보존이 이루어지고 있어, 장애 발생 시 데이터 유실 가능성을 완전히 배제할 수 없습니다. 이를 개선하기 위해 **자동화된 정기 백업 시스템을 도입**하고, 복구 테스트를 병행하여 비상 상황에서도 빠르게 서비스를 복원할 수 있는 체계를 구축할 계획입니다. AWS RDS 스냅샷 자동화, S3 백업 보관 정책, 정기 복구 테스트를 통해 장애 시에도 데이터 손실 없이 신속히 복원할 수 있는 체계를 마련합니다.
    

## 5.3. AI & 데이터 처리

- **클러스터링 결과 지속 평가 및 주기적 재튜닝**
    
    현재의 클러스터링 모델은 초기 설정된 하이퍼파라미터에 기반해 동작하고 있어, 시간이 지남에 따라 데이터 특성과 맞지 않는 결과가 발생할 수 있습니다. 이에 따라 향후에는 **클러스터링 결과를 지속적으로 평가**하고, **주기적으로 k값, 임베딩 방식 등의 파라미터를 재튜닝**함으로써 최신 뉴스 흐름을 반영할 수 있도록 개선할 계획입니다. Silhouette, HHI 등의 품질 지표를 배치로 모니터링하고, 파라미터(k, 임베딩 방식)를 자동 추천·갱신해 최신 뉴스 특성에 최적화된 클러스터링을 유지합니다.
    
- **멀티스레딩 구조 도입**
    
    현재는 하나의 스레드가 모든 토픽에 대해 수집, 전처리, 임베딩, 클러스터링 등의 파이프라인을 순차적으로 처리하고 있어, 전체 처리 시간이 데이터량에 비례해 증가하는 구조입니다. 이를 해결하기 위해 향후에는 **토픽별로 독립적인 스레드를 생성하여 각 파이프라인을 병렬로 실행**하는 **멀티스레딩** **구조로 개선**할 계획입니다. 이를 통해 전체 처리 시간을 단축하고, 대량의 토픽을 동시에 다뤄야 하는 상황에서도 높은 처리 효율을 유지할 수 있을 것으로 예상합니다. 토픽별 파이프라인(수집→전처리→임베딩→클러스터링)을 독립 스레드로 병렬 실행하여 처리 시간을 단축하고, 대량 토픽 동시 처리 시에도 안정적인 성능을 보장합니다.
    

## 5.4. 배포

- **인프라 코드화(IaC) 및 오토스케일링 강화**
    
    Terraform/CloudFormation으로 AWS 리소스를 정의하고, ECS Fargate 서비스에 CPU·메모리 기반 자동 스케일링 정책을 적용해 트래픽 변화에 유연히 대응합니다.
    
- **모니터링·알림 체계 고도화**
    
    CloudWatch Metrics 및 Grafana 대시보드를 구축해 서비스 전체 메트릭을 실시간 시각화하고, 임계치 초과 시 SNS→Slack/이메일 알림으로 운영 대응 속도를 높입니다.
